// =============================================================================
// BIBLIOBOT BACKEND - RAG CHAIN SERVICE (CONVERSATIONAL RETRIEVAL QA)
// =============================================================================

import { ChatMessage } from '@/types';
import { qdrantService } from '@/services/qdrantService';
import { systemPromptService } from '@/services/systemPromptService';
import { logger, logOpenAI, logError } from '@/utils/logger';
import { config } from '@/config';
import { OpenAI } from 'openai';

// Configuration du client OpenAI pour Azure
const openai = new OpenAI({
  apiKey: config.openai.apiKey,
  baseURL: `${config.openai.endpoint}openai/deployments/${config.openai.deploymentName}`,
  defaultQuery: { 'api-version': config.openai.apiVersion },
  defaultHeaders: {
    'api-key': config.openai.apiKey,
  },
});

/**
 * RAG Chain Service - Impl√©mente un Conversational Retrieval QA Chain
 * Similaire au noeud Flowise mais optimis√© et professionnel
 */
class RAGChainService {
  // Seuils de pertinence (AJUST√â pour pr√©cision)
  private readonly SIMILARITY_THRESHOLD = 0.55; // ‚úÖ Plus strict pour √©viter le bruit
  private readonly MIN_RELEVANT_DOCS = 1; // Nombre minimum de docs pertinents requis
  private readonly TOP_K = 5; // ‚úÖ Moins de docs pour plus de concentration

  // Param√®tres LLM (COMME FLOWISE)
  private readonly TEMPERATURE = 0.4; // ‚úÖ Plus factuel (moins d'hallucinations)
  private readonly MAX_TOKENS = 500; // ‚úÖ Concis mais suffisant pour explications p√©dagogiques
  private readonly TOP_P = 0.9; // Nucleus sampling
  private readonly FREQUENCY_PENALTY = 0.3; // R√©duit r√©p√©titions
  private readonly PRESENCE_PENALTY = 0.2; // Encourage diversit√© minimale

  /**
   * G√©n√©rer une r√©ponse avec RAG Chain strict
   */
  async generateResponse(
    userMessage: string,
    conversationHistory: ChatMessage[],
    sessionId: string,
    chatbot: string = 'bibliobot'
  ): Promise<{
    response: string;
    tokensUsed: number;
    responseTime: number;
    sources: string[];
    relevantDocsCount: number;
    hasRelevantContext: boolean;
  }> {
    const startTime = Date.now();

    try {
      // √âTAPE 1: Reformuler la question avec le contexte de conversation
      const reformulatedQuestion = await this.reformulateWithHistory(
        userMessage,
        conversationHistory
      );

      logger.info(`üîÑ Question reformul√©e: "${reformulatedQuestion}"`);

      // √âTAPE 2: Recherche vectorielle avec TOP_K = 7 (comme Flowise)
      const vectorResults = await qdrantService.searchForChatbot(
        reformulatedQuestion,
        chatbot as 'studybot' | 'bibliobot',
        this.TOP_K // ‚úÖ 5 documents (plus pr√©cis)
      );

      // √âTAPE 3: FILTRAGE STRICT par score de similarit√©
      const relevantDocs = vectorResults.filter(
        doc => doc.score >= this.SIMILARITY_THRESHOLD
      );

      logger.info(
        `üìä Recherche vectorielle: ${vectorResults.length} r√©sultats, ${relevantDocs.length} pertinents (seuil: ${this.SIMILARITY_THRESHOLD})`
      );
      logger.info(
        `   Scores: ${vectorResults.map(r => r.score.toFixed(3)).join(', ')}`
      );

      // √âTAPE 4: V√©rifier si on a du contexte pertinent
      const hasRelevantContext = relevantDocs.length >= this.MIN_RELEVANT_DOCS;

      if (!hasRelevantContext) {
        logger.warn('‚ö†Ô∏è Pas de contexte pertinent trouv√© - Le LLM r√©pondra sans contexte');
      }

      // √âTAPE 5: Construire le contexte (vide si pas de docs pertinents)
      const contextSources = relevantDocs.map(doc => doc.content);

      // √âTAPE 6: Construire les messages avec prompt STRICT
      const messages = await this.buildStrictMessages(
        userMessage,
        conversationHistory,
        contextSources
      );

      // √âTAPE 7: Appel LLM avec param√®tres anti-hallucination
      const completion = await openai.chat.completions.create({
        model: config.openai.model,
        messages,
        max_tokens: this.MAX_TOKENS,
        temperature: this.TEMPERATURE, // ‚ö° TR√àS BAS pour √©viter hallucinations (0.1)
        top_p: this.TOP_P,
        frequency_penalty: this.FREQUENCY_PENALTY,
        presence_penalty: this.PRESENCE_PENALTY,
        stream: false,
      });

      const responseTime = Date.now() - startTime;
      const response = completion.choices[0]?.message?.content || '';
      const tokensUsed = completion.usage?.total_tokens || 0;

      // Logger la requ√™te
      logOpenAI(
        'rag_chain_completion',
        config.openai.model,
        tokensUsed,
        responseTime,
        sessionId
      );

      // √âTAPE 8: Post-traitement de la r√©ponse
      const cleanedResponse = this.cleanResponse(response);

      return {
        response: cleanedResponse,
        tokensUsed,
        responseTime,
        sources: contextSources,
        relevantDocsCount: relevantDocs.length,
        hasRelevantContext: true
      };

    } catch (error) {
      logError(error as Error, {
        service: 'ragChain',
        action: 'generateResponse',
        sessionId
      });

      throw error;
    }
  }

  /**
   * Reformuler la question avec l'historique de conversation
   * REPHRASE PROMPT (comme Flowise)
   */
  private async reformulateWithHistory(
    question: string,
    history: ChatMessage[]
  ): Promise<string> {
    // Si pas d'historique, retourner la question telle quelle
    if (history.length === 0) {
      return question;
    }

    // Prendre les 3 derniers √©changes pour le contexte
    const recentHistory = history.slice(-6); // 3 user + 3 assistant

    // Si la question est d√©j√† compl√®te (plus de 10 mots), pas besoin de reformuler
    if (question.split(' ').length > 10) {
      return question;
    }


    try {
      // ‚úÖ REPHRASE PROMPT (exactement comme Flowise)
      const chatHistoryText = recentHistory
        .map(msg => `${msg.role === 'user' ? 'Human' : 'Assistant'}: ${msg.content}`)
        .join('\n');

      const reformulationPrompt = `Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.

Chat History:
${chatHistoryText}

Follow Up Input: ${question}

Standalone Question:`;

      const response = await openai.chat.completions.create({
        model: config.openai.model,
        messages: [{ role: 'user', content: reformulationPrompt }],
        max_tokens: 100,
        temperature: 0.3
      });

      const reformulated = response.choices[0]?.message?.content?.trim() || question;
      return reformulated;

    } catch (error) {
      logger.warn('‚ö†Ô∏è Erreur reformulation, utilisation question originale');
      return question;
    }
  }

  /**
   * Construire les messages avec prompt STRICT anti-hallucination
   * ORDRE IMPORTANT (comme Flowise):
   * 1. R√àGLES RAG CHAIN (techniques)
   * 2. PROMPT DASHBOARD (m√©tier)
   * 3. CONTEXTE (documents)
   */
  private async buildStrictMessages(
    userMessage: string,
    conversationHistory: ChatMessage[],
    contextSources: string[]
  ): Promise<Array<{ role: 'system' | 'user' | 'assistant'; content: string }>> {
    const messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [];

    // R√©cup√©rer le prompt syst√®me actif depuis le dashboard
    let dashboardPrompt = '';
    try {
      const activePrompt = await systemPromptService.getActivePrompt();
      if (activePrompt && activePrompt.content) {
        dashboardPrompt = activePrompt.content;
        logger.info('‚úÖ Prompt dashboard charg√© (via RAG Chain)');
      }
    } catch (error) {
      logger.warn('‚ö†Ô∏è Erreur chargement prompt dashboard');
    }

    // Construire le contexte
    const contextBlock = this.buildContextBlock(contextSources);

    // RESPONSE PROMPT (COMME FLOWISE)
    // Prompt syst√®me dashboard + contexte (comme dans Flowise Response Prompt)
    const strictSystemPrompt = `${dashboardPrompt || 'Nom de l\'Assistant : BiblioBot\n\nInstruction :\nTu es un assistant virtuel d√©di√© exclusivement aux services et ressources de la biblioth√®que de emlyon.'}

${contextBlock}

R√àGLES DE R√âPONSE:
1. Utilise le contexte fourni pour r√©pondre de mani√®re pr√©cise et utile
2. FORMATAGE DES LIENS (OBLIGATOIRE):
   - TOUJOURS utiliser UNIQUEMENT le format Markdown pour les liens: [Texte descriptif](URL_compl√®te)
   - JAMAIS g√©n√©rer du HTML (<a href=...), JAMAIS √©crire l'URL compl√®te en texte brut
   - Le texte du lien doit √™tre court et descriptif (nom de la ressource, du service, etc.)
   - L'URL doit TOUJOURS √™tre compl√®te avec https://
   - Exemples CORRECTS:
     ‚úÖ "Consultez [ENI Belearn](https://library.em-lyon.com/...)"
     ‚úÖ "Acc√©dez aux [ressources presse](https://library.em-lyon.com/Default/presse.aspx)"
     ‚úÖ "[T√©l√©charger Lean Library](https://download.leanlibrary.com/download-lean-library-em-lyon)"
   - Exemples INCORRECTS:
     ‚ùå "Consultez https://library.em-lyon.com/Default/doc/SYRACUSE/98582/..." (URL brute)
     ‚ùå '<a href="...">texte</a>' (HTML interdit)
     ‚ùå 'presse.aspx" target="_blank"...' (HTML malform√©)
3. FORMATAGE DES LISTES:
   - Toujours aller √† la ligne apr√®s deux-points (:)
   - Toujours aller √† la ligne entre chaque √©l√©ment num√©rot√©
4. Longueur: Adapte la longueur selon le besoin (concis mais complet)
5. Sois naturel, conversationnel et professionnel`;

    messages.push({
      role: 'system',
      content: strictSystemPrompt
    });

    // Ajouter l'historique r√©cent (max 6 messages = 3 √©changes)
    const recentHistory = conversationHistory.slice(-6);
    for (const msg of recentHistory) {
      messages.push({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      });
    }

    // Ajouter le message utilisateur actuel
    messages.push({
      role: 'user',
      content: userMessage
    });

    return messages;
  }

  /**
   * Construire le bloc de contexte
   */
  private buildContextBlock(sources: string[]): string {
    if (sources.length === 0) {
      return '\n=== CONTEXTE ===\nAucune information pertinente trouv√©e.\n================\n';
    }

    const contextItems = sources.map((source, index) => {
      return `${index + 1}. ${source}`;
    }).join('\n\n');

    return `
=== CONTEXTE FOURNI ===
${contextItems}
========================

Utilise UNIQUEMENT les informations ci-dessus pour r√©pondre.`;
  }


  /**
   * Nettoyer la r√©ponse (corriger les liens cass√©s, formatage, etc.)
   */
  private cleanResponse(response: string): string {
    let cleaned = response;

    // 0. ‚ö° CRITIQUE: Supprimer TOUT code HTML malform√© g√©n√©r√© par erreur
    // Pattern 1: Fragments HTML orphelins comme 'presse.aspx" target="_blank" rel="noopener noreferrer" class="bot-link">texte'
    // Ces fragments apparaissent quand le LLM g√©n√®re du HTML au lieu de Markdown
    cleaned = cleaned.replace(/[a-zA-Z0-9\-_.]+\.(?:aspx|html|php|htm)["'][^>]*>([^<\n]+)/g, '$1');
    
    // Pattern 2: Balises <a> compl√®tes mal form√©es (sans href ou href cass√©)
    // Ex: <a href="presse.aspx">texte</a> ‚Üí [texte](presse.aspx)
    cleaned = cleaned.replace(/<a\s+[^>]*href=["']([^"']+)["'][^>]*>([^<]+)<\/a>/gi, '[$2]($1)');
    
    // Pattern 3: Balises HTML orphelines (ouverture ou fermeture seules)
    cleaned = cleaned.replace(/<\/?a[^>]*>/gi, '');
    
    // Pattern 4: Attributs HTML orphelins (target="_blank", rel=..., class=...)
    cleaned = cleaned.replace(/(?:target|rel|class)=["'][^"']*["']/gi, '');

    // 1. S'assurer que les deux-points sont suivis d'un saut de ligne double
    // Ex: "Voici: liste" ‚Üí "Voici:\n\nliste"
    cleaned = cleaned.replace(/:(?!\n\n)(\s*)/g, ':\n\n');

    // 2. S'assurer que les √©l√©ments de liste num√©rot√©e sont sur une nouvelle ligne
    // Ex: "1. Item 2. Item" ‚Üí "1. Item\n2. Item"
    // On cherche un chiffre suivi d'un point, pr√©c√©d√© d'espace mais pas de saut de ligne
    cleaned = cleaned.replace(/(?<!\n)(\s+)(\d+\.)/g, '\n$2');

    // 3. S'assurer qu'il y a un espace apr√®s le num√©ro de liste
    // Ex: "1.Item" ‚Üí "1. Item"
    cleaned = cleaned.replace(/(\d+\.)([^\s])/g, '$1 $2');

    // 4. Corriger les liens Markdown mal format√©s
    // Ex: [texte]https://url ‚Üí [texte](https://url)
    cleaned = cleaned.replace(/\[([^\]]+)\](https?:\/\/[^\s)]+)/g, '[$1]($2)');

    // 5. Corriger les espaces dans les emails
    // Ex: library@ em-lyon.com ‚Üí library@em-lyon.com
    cleaned = cleaned.replace(/(\w+)@\s+(\S+)/g, '$1@$2');

    // 6. S'assurer que les emails library ont le bon format
    cleaned = cleaned.replace(/library\s*@\s*em-lyon\.com/gi, 'library@em-lyon.com');

    // 7. ‚ö° CORRIGER URLs PROTOCOLE-RELATIVE (//domain.com ‚Üí https://domain.com)
    // CRITIQUE: √âvite que les liens deviennent relatifs et cass√©s dans le frontend
    cleaned = cleaned.replace(/\[([^\]]+)\]\((\/\/[^)]+)\)/g, '[$1](https:$2)');
    cleaned = cleaned.replace(/(?<!https?:)(\/\/[a-zA-Z0-9][^\s)]*)/g, 'https:$1');

    // 8. Corriger les URLs seules avec parenth√®ses inutiles (mais pas dans Markdown)
    // Ex: (https://url.com) qui n'est pas pr√©c√©d√© de ] ‚Üí https://url.com
    cleaned = cleaned.replace(/(?<!\])\((https?:\/\/[^\s)]+)\)/g, '$1');

    // 9. Enlever les doubles espaces MAIS GARDER les sauts de ligne
    // On remplace seulement les espaces horizontaux multiples par un seul espace
    cleaned = cleaned.replace(/[ \t]{2,}/g, ' ');

    // 10. S'assurer qu'il n'y a pas plus de 2 sauts de ligne cons√©cutifs
    cleaned = cleaned.replace(/\n{3,}/g, '\n\n');

    // 11. Trim
    cleaned = cleaned.trim();

    return cleaned;
  }
}

// Instance singleton
export const ragChainService = new RAGChainService();
export default ragChainService;
